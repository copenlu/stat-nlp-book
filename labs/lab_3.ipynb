{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab_3",
      "provenance": [],
      "collapsed_sections": [
        "SqCF2Bk0GiWr",
        "BIGas9GNJBM6",
        "wfu0XTsvI1-1",
        "vOF6DuOANBLK"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "07c71aa27af74d50aeb88fba1bf9f21b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7aa90a2c194345c4a17b421278fa5c4b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1cdc9528fc3a48f285357816ffd71ae5",
              "IPY_MODEL_08e1fb8dbeb7489aba0abf370b311f9d"
            ]
          }
        },
        "7aa90a2c194345c4a17b421278fa5c4b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1cdc9528fc3a48f285357816ffd71ae5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_6564444f31974cb0ade65b26e44162ad",
            "_dom_classes": [],
            "description": "Evaluation: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 54,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 54,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_826b133eeba34e0d801113b50aee84b6"
          }
        },
        "08e1fb8dbeb7489aba0abf370b311f9d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9a3c3bd03808430984b5c4c4038e885a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 54/54 [00:06&lt;00:00,  8.22it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9fa6dd95cdbd43af9d27c93c54fc28e2"
          }
        },
        "6564444f31974cb0ade65b26e44162ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "826b133eeba34e0d801113b50aee84b6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9a3c3bd03808430984b5c4c4038e885a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9fa6dd95cdbd43af9d27c93c54fc28e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SqCF2Bk0GiWr",
        "colab_type": "text"
      },
      "source": [
        "# Building a Language Model with Pytorch\n",
        "\n",
        "In this lab exercise, we'll build an LSTM language model using the WikiText dataset which can generate novel sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "70HL69ki43xO",
        "colab_type": "text"
      },
      "source": [
        "Link to the notebook: https://tinyurl.com/y2zz2qu8\n",
        "**Copy the notebook to your GDrive to edit.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vKjNPo57FTJ8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# magic commands to make sure changes to external packages are automatically loaded and plots are displayed in the notebook\n",
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7aI_mECQqhS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import random\n",
        "import numpy as np\n",
        "from typing import List, Tuple\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch import nn\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.optim import Adam, RMSprop\n",
        "import nltk"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkmVtpi_MxEc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def enforce_reproducibility(seed=42):\n",
        "    # Sets seed manually for both CPU and CUDA\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    # For atomic operations there is currently \n",
        "    # no simple way to enforce determinism, as\n",
        "    # the order of parallel operations is not known.\n",
        "    # CUDNN\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    # System based\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "enforce_reproducibility()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BIGas9GNJBM6",
        "colab_type": "text"
      },
      "source": [
        "# RNNs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDrTKqi08j4m",
        "colab_type": "text"
      },
      "source": [
        "![Karpathy blog rnn example](https://karpathy.github.io/assets/rnn/diags.jpeg)\n",
        "\n",
        "Source: https://karpathy.github.io/2015/05/21/rnn-effectiveness/\n",
        "\n",
        "Recurrent neural nets (RNNs) are a widely used neural network architecture for working with sequence data. As seen above, they can be used for a variety of problems which work with sequences. They are based on performing computations which consider both a given input and a **state**, which is updated at every step on the input sequence. How this state is kept and the internal calculations of an RNN can differ. There are generally three main types of RNN cells used in practice: vanilla RNNs, GRU, and LSTM. GRUs and LSTMs differ from vanilla RNNs in that they use **gating mechanisms** in order to mitigate vanishing gradients, which are a known problem with vanilla RNNs, and are better at capturing long-term dependencies. We will use the LSTM cell in this lab."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPhxrOAOLu1l",
        "colab_type": "text"
      },
      "source": [
        "# Recap on Data Preparation for RNNs \n",
        "## Packing\n",
        "We'll start with a recap of the steps to prepare textual input for training an RNN and we'll walk through an show-case of packing sequences."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rOPCP4rEpX1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "7b3a2a6a-d3bb-48f3-8715-b081a39760fe"
      },
      "source": [
        "# We want to run LSTM on a batch with 3 sentences\n",
        "sents = ['The word of the Lord came to Zechariah son of Iddo the prophet.',  # len = 13\n",
        "        'fruit flies like a banana',      # len = 5\n",
        "        'Fruit flies live on a banana']    # len = 6\n",
        "\n",
        "# Step 1: Construct Vocabulary\n",
        "vocab = ['<pad>'] + sorted(set([token for sent in sents for token in sent.split()]))\n",
        "\n",
        "#Step 2: Load indexed data (list of instances, where each instance is list of character indices)\n",
        "vectorized_seqs = [[vocab.index(tok) for tok in sent.split()]for sent in sents]\n",
        "\n",
        "#Step 3: Make Model\n",
        "embed = torch.nn.Embedding(len(vocab), 4) # embedding_dim = 4\n",
        "lstm = torch.nn.LSTM(input_size=4, hidden_size=5, batch_first=True) # input_dim = 4, hidden_dim = 5\n",
        "\n",
        "#Step 4: Pad instances with 0s till max length sequence\n",
        "# get the length of each seq in your batch\n",
        "seq_lengths = torch.LongTensor(list(map(len, vectorized_seqs)))\n",
        "\n",
        "seq_tensor = torch.tensor(torch.zeros((len(vectorized_seqs), seq_lengths.max()))).long()\n",
        "\n",
        "for idx, (seq, seqlen) in enumerate(zip(vectorized_seqs, seq_lengths)):\n",
        "    seq_tensor[idx, :seqlen] = torch.LongTensor(seq)\n",
        "seq_tensor"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:20: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4, 19, 13, 17,  3,  8, 18,  5, 16, 13,  2, 17, 15],\n",
              "        [10,  9, 11,  6,  7,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [ 1,  9, 12, 14,  6,  7,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwacR6fdG5Rm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "f48235d7-3ec2-4d48-f7e9-223051ce93f3"
      },
      "source": [
        "# Step 5: Sort instances by sequence length in descending order \n",
        "# this step is not compulsory, where the packing functions have a parameter enforce_sorted, which can be set to False\n",
        "seq_lengths, perm_idx = seq_lengths.sort(0, descending=True)\n",
        "seq_tensor = seq_tensor[perm_idx]\n",
        "seq_tensor"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 4, 19, 13, 17,  3,  8, 18,  5, 16, 13,  2, 17, 15],\n",
              "        [ 1,  9, 12, 14,  6,  7,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [10,  9, 11,  6,  7,  0,  0,  0,  0,  0,  0,  0,  0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SKbaeryHC9H",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "aaefbbd2-f639-4470-bbe8-015234a99151"
      },
      "source": [
        "# Calling pack_padded_sequence with instances and sequence lengths\n",
        "# Here we give an idea of the packing functionality, \n",
        "# which is important for training RNN on text with variable lenght\n",
        "packed_input = torch.nn.utils.rnn.pack_padded_sequence(seq_tensor, seq_lengths.cpu().numpy(), batch_first=True)\n",
        "# packed_input (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
        "packed_input"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([ 4,  1, 10, 19,  9,  9, 13, 12, 11, 17, 14,  6,  3,  6,  7,  8,  7, 18,\n",
              "         5, 16, 13,  2, 17, 15]), batch_sizes=tensor([3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YORCY4nzHgYO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "b9eb58e2-2f64-4437-91af-2bb881063e4a"
      },
      "source": [
        "# Step 6: Let's now proceed with the network transformations and embed the instances\n",
        "embedded_seq_tensor = embed(seq_tensor)\n",
        "embedded_seq_tensor"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
              "         [ 0.5750, -0.6417, -2.2064, -0.7508],\n",
              "         [-0.4880,  1.1914, -0.8140, -0.7360],\n",
              "         [ 0.3466, -0.1973, -1.0546,  1.2780],\n",
              "         [-0.7279, -0.5594, -0.7688,  0.7624],\n",
              "         [-1.3847, -0.8712, -0.2234,  1.7174],\n",
              "         [-0.1722,  0.5238,  0.0566,  0.4263],\n",
              "         [-0.7581,  1.0783,  0.8008,  1.6806],\n",
              "         [ 1.4451,  0.8564,  2.2181,  0.5232],\n",
              "         [-0.4880,  1.1914, -0.8140, -0.7360],\n",
              "         [-0.7521,  1.6487, -0.3925, -1.4036],\n",
              "         [ 0.3466, -0.1973, -1.0546,  1.2780],\n",
              "         [-0.0978,  1.8446, -1.1845,  1.3835]],\n",
              "\n",
              "        [[ 0.6784, -1.2345, -0.0431, -1.6047],\n",
              "         [ 0.3189, -0.4245,  0.3057, -0.7746],\n",
              "         [-0.9138, -0.6581,  0.0780,  0.5258],\n",
              "         [-1.4032,  0.0360, -0.0635,  0.6756],\n",
              "         [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
              "         [-0.2316,  0.0418, -0.2516,  0.8599],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055]],\n",
              "\n",
              "        [[-1.5576,  0.9956, -0.8798, -0.6011],\n",
              "         [ 0.3189, -0.4245,  0.3057, -0.7746],\n",
              "         [-1.2742,  2.1228, -1.2347, -0.4879],\n",
              "         [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
              "         [-0.2316,  0.0418, -0.2516,  0.8599],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055],\n",
              "         [ 1.9269,  1.4873,  0.9007, -2.1055]]], grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eeVeo5UQHajy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 462
        },
        "outputId": "7d6ffcd8-ce37-49b2-8589-4d23a7e5c79f"
      },
      "source": [
        "# Step 7: Call pack_padded_sequence with embeded instances and sequence lengths\n",
        "packed_input = torch.nn.utils.rnn.pack_padded_sequence(embedded_seq_tensor, seq_lengths.cpu().numpy(), batch_first=True)\n",
        "# packed_input (PackedSequence is NamedTuple with 2 attributes: data and batch_sizes\n",
        "packed_input"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PackedSequence(data=tensor([[ 1.6423, -0.1596, -0.4974,  0.4396],\n",
              "        [ 0.6784, -1.2345, -0.0431, -1.6047],\n",
              "        [-1.5576,  0.9956, -0.8798, -0.6011],\n",
              "        [ 0.5750, -0.6417, -2.2064, -0.7508],\n",
              "        [ 0.3189, -0.4245,  0.3057, -0.7746],\n",
              "        [ 0.3189, -0.4245,  0.3057, -0.7746],\n",
              "        [-0.4880,  1.1914, -0.8140, -0.7360],\n",
              "        [-0.9138, -0.6581,  0.0780,  0.5258],\n",
              "        [-1.2742,  2.1228, -1.2347, -0.4879],\n",
              "        [ 0.3466, -0.1973, -1.0546,  1.2780],\n",
              "        [-1.4032,  0.0360, -0.0635,  0.6756],\n",
              "        [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
              "        [-0.7279, -0.5594, -0.7688,  0.7624],\n",
              "        [ 1.2791,  1.2964,  0.6105,  1.3347],\n",
              "        [-0.2316,  0.0418, -0.2516,  0.8599],\n",
              "        [-1.3847, -0.8712, -0.2234,  1.7174],\n",
              "        [-0.2316,  0.0418, -0.2516,  0.8599],\n",
              "        [-0.1722,  0.5238,  0.0566,  0.4263],\n",
              "        [-0.7581,  1.0783,  0.8008,  1.6806],\n",
              "        [ 1.4451,  0.8564,  2.2181,  0.5232],\n",
              "        [-0.4880,  1.1914, -0.8140, -0.7360],\n",
              "        [-0.7521,  1.6487, -0.3925, -1.4036],\n",
              "        [ 0.3466, -0.1973, -1.0546,  1.2780],\n",
              "        [-0.0978,  1.8446, -1.1845,  1.3835]],\n",
              "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([3, 3, 3, 3, 3, 2, 1, 1, 1, 1, 1, 1, 1]), sorted_indices=None, unsorted_indices=None)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PQyp6kKgIXvT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Step 8: Forward with LSTM\n",
        "packed_output, (ht, ct) = lstm(packed_input)\n",
        "\n",
        "# Step 9: Call unpack_padded_sequences if required / or just pick last hidden vector\n",
        "output, input_sizes = torch.nn.utils.rnn.pad_packed_sequence(packed_output, batch_first=True)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kj2BQBKgIo3h",
        "colab_type": "text"
      },
      "source": [
        "Summary of Shape Transformations\n",
        "\n",
        "(batch_size X max_seq_len X embedding_dim) --> Sort by seqlen ---> (batch_size X max_seq_len X embedding_dim)\n",
        "\n",
        "(batch_size X max_seq_len X embedding_dim) --->      Pack     ---> (batch_sum_seq_len X embedding_dim)\n",
        "\n",
        "(batch_sum_seq_len X embedding_dim)        --->      LSTM     ---> (batch_sum_seq_len X hidden_dim)\n",
        "\n",
        "(batch_sum_seq_len X hidden_dim)           --->    UnPack     ---> (batch_size X max_seq_len X hidden_dim)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wfu0XTsvI1-1",
        "colab_type": "text"
      },
      "source": [
        "## Bucketing\n",
        "Another useful trick when training NLP models is to group instances of similar lenghts in the same batch which leads to minimal padding, e.g. a batch with instances of lenght 5, 5, 6 will be padded to lenght 6, while a batch with instances of lenght 5, 5, 13 will be padded to lenght 13 and will also take more time for processing.\n",
        "\n",
        "On the other hand, you still want some randomness in the batches and the ultimate solution would be to have buckets with N instances with similar lenght and shuffle them into K batches.\n",
        "\n",
        "The Torch text library contains an example implementation for this purpose -- Bucket Iterator (https://torchtext.readthedocs.io/en/latest/data.html#bucketiterator)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vOF6DuOANBLK",
        "colab_type": "text"
      },
      "source": [
        "# Building a Language Model\n",
        "Next, we'll build a Language Model with a RNN. Language Models are trained to assign probabilities to sequences of words. They can be used to verify how likely is a particular sequence of text, e.g. if it sounds grammatical and complies to the rules of a language. Language models predict the next word in a sequence given the past context. A best LM is one that best predicts unseen words. LMs are evaluated with Perplexity, which is the inverse probability of the test set, normalized by the number of words:\n",
        "\n",
        "\\begin{equation}\n",
        "\\mathrm{PP}(W)=\\sqrt[N]{\\prod_{i=1}^{N} \\frac{1}{P\\left(w_{i} \\mid w_{1} \\ldots w_{i-1}\\right)}}\n",
        "\\end{equation}\n",
        "\n",
        "Minimizing perplexity is the same as maximising probability of the correct prediction."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xy7v99c4QVbH",
        "colab_type": "text"
      },
      "source": [
        "# Upload the dataset \n",
        "\n",
        "For training the Language Model, we'll be using the [WikiText-2 dataset](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJKFOvdZPqb_",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 191
        },
        "outputId": "33a1380b-0cf3-4f57-a9b1-760265188238"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e47648fe-0819-49e4-8927-67b54ea04a22\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e47648fe-0819-49e4-8927-67b54ea04a22\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving wiki.test.tokens to wiki.test.tokens\n",
            "Saving wiki.train.tokens to wiki.train.tokens\n",
            "Saving wiki.valid.tokens to wiki.valid.tokens\n",
            "User uploaded file \"wiki.test.tokens\" with length 1256449 bytes\n",
            "User uploaded file \"wiki.train.tokens\" with length 10797148 bytes\n",
            "User uploaded file \"wiki.valid.tokens\" with length 1121681 bytes\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eqr1sIwdPLh8",
        "colab_type": "text"
      },
      "source": [
        "# Read in the data\n",
        "\n",
        "The dataset is already tokenized and split into test, validation and training datasets. \n",
        "\n",
        "For preprocessing, we don't have to take care of tokenization and will only replace new lines with an \\<eos> token. \n",
        "\n",
        "We also have to take care of converting the text into sequences of ids with a vocabulary object that'll keep the mapping (in lab_02, we used a ready-made tokenizer, which also took care of converting the text to ids as the ids have to match the word ids in the embedding matrix provided by the same package)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SGqAmwcFP5RD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Vocab:\n",
        "  def __init__(self):\n",
        "    self.word2idx = {}\n",
        "    self.idx2word = []\n",
        "\n",
        "  def add_word(self, word):\n",
        "    if word not in self.word2idx:\n",
        "      self.idx2word.append(word)\n",
        "      self.word2idx[word] = len(self.idx2word) - 1\n",
        "    return self.word2idx[word]\n",
        "    \n",
        "  def to_words(self, ids):\n",
        "    return [self.idx2word[idx] for idx in ids]\n",
        "\n",
        "  def to_ids(self, words):\n",
        "    return [self.add_word(word) for word in words]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.idx2word)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHdDHswFj46a",
        "colab_type": "text"
      },
      "source": [
        "Next, we'll build the vocabulary with the words from the splits. \n",
        "\n",
        "As the dataset is relatively small, we can use only the words that appear in it. This way we can also customise whether we care about upper-case tokens or want all of them to be lower-case or to include domain-specific tokens."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n0jnFdN9jNGS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "383f0ff7-e3b7-42e8-a0ad-387b856f075b"
      },
      "source": [
        "vocabulary = Vocab()\n",
        "vocabulary.add_word('<eos>') # include a token indicating the end of a string\n",
        "vocabulary.add_word('<pad>') # include a token for padding\n",
        "\n",
        "for filename in ['wiki.test.tokens', 'wiki.train.tokens', 'wiki.valid.tokens']:\n",
        "  with open(filename) as out:\n",
        "    for line in out:\n",
        "      tokens = line.strip().split(' ')\n",
        "      for token in tokens:\n",
        "          vocabulary.add_word(token)\n",
        "\n",
        "len(vocabulary)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33280"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "criyWhXEkej0",
        "colab_type": "text"
      },
      "source": [
        "**Note.** If the dataset is large, we can use a standard list of tokens to build a vocabulary, e.g. the NLTK English vocabulary, which will results in a larger embedding matrix (NLTK contains 236736 tokens and our vocabulary is of 33278 tokens). We can also use the vocabulary of a tokenizer we employ for pre-processing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eUTf-Q-tj0yl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c4d15314-5c09-4018-a90a-07915348816a"
      },
      "source": [
        "from nltk.corpus import words\n",
        "import nltk\n",
        "nltk.download('words')\n",
        "len(list(words.words()))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package words to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/words.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "236736"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JgDLs-yllZiC",
        "colab_type": "text"
      },
      "source": [
        "The dataset reader will read the whole file with Wikipedia pages and split the text to consecutive sequences of length seq_len, where each sequence will be one instance of the dataset. \n",
        "\n",
        "**Note.** One could also split first to different Wikipedia pages so that there aren't instances with text for different Wiki pages. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EN1wRU4YoZ49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "207594e0-ecdb-411d-ff1e-a9d58948f97d"
      },
      "source": [
        "!head -20 wiki.test.tokens "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " \n",
            " = Robert <unk> = \n",
            " \n",
            " Robert <unk> is an English film , television and theatre actor . He had a guest @-@ starring role on the television series The Bill in 2000 . This was followed by a starring role in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . He had a guest role in the television series Judge John <unk> in 2002 . In 2004 <unk> landed a role as \" Craig \" in the episode \" Teddy 's Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . He was cast in the 2005 theatre productions of the Philip Ridley play Mercury Fur , which was performed at the Drum Theatre in Plymouth and the <unk> <unk> Factory in London . He was directed by John <unk> and starred alongside Ben <unk> , Shane <unk> , Harry Kent , Fraser <unk> , Sophie Stanton and Dominic Hall . \n",
            " In 2006 , <unk> starred alongside <unk> in the play <unk> written by Mark <unk> . He appeared on a 2006 episode of the television series , Doctors , followed by a role in the 2007 theatre production of How to Curse directed by <unk> <unk> . How to Curse was performed at Bush Theatre in the London Borough of <unk> and Fulham . <unk> starred in two films in 2008 , <unk> <unk> by filmmaker Paris <unk> , and <unk> Punch directed by <unk> Blackburn . In May 2008 , <unk> made a guest appearance on a two @-@ part episode arc of the television series Waking the Dead , followed by an appearance on the television series <unk> in November 2008 . He had a recurring role in ten episodes of the television series <unk> in 2010 , as \" <unk> Fletcher \" . <unk> starred in the 2011 film <unk> directed by Paris <unk> . \n",
            " \n",
            " = = Career = = \n",
            " \n",
            " \n",
            " = = = 2000 – 2005 = = = \n",
            " \n",
            " In 2000 <unk> had a guest @-@ starring role on the television series The Bill ; he portrayed \" Scott Parry \" in the episode , \" In Safe Hands \" . <unk> starred as \" Scott \" in the play Herons written by Simon Stephens , which was performed in 2001 at the Royal Court Theatre . A review of <unk> 's performance in The Independent on Sunday described him as \" horribly menacing \" in the role , and he received critical reviews in The Herald , and Evening Standard . He appeared in the television series Judge John <unk> in 2002 as \" <unk> <unk> \" in the episode \" Political <unk> \" , and had a role as a different character \" Toby Steele \" on The Bill . \n",
            " He had a recurring role in 2003 on two episodes of The Bill , as character \" Connor Price \" . In 2004 <unk> landed a role as \" Craig \" in the episode \" Teddy 's Story \" of the television series The Long Firm ; he starred alongside actors Mark Strong and Derek Jacobi . <unk> starred as \" Darren \" , in the 2005 theatre productions of the Philip Ridley play Mercury Fur . It was performed at the Drum Theatre in Plymouth , and the <unk> <unk> Factory in London . He was directed by John <unk> and starred alongside Ben <unk> , Shane <unk> , Harry Kent , Fraser <unk> , Sophie Stanton and Dominic Hall . <unk> received a favorable review in The Daily Telegraph : \" The acting is <unk> intense , with <unk> performances from Ben <unk> ( now <unk> from his performance as Trevor <unk> 's Hamlet ) , Robert <unk> , Shane <unk> and Fraser <unk> . \" The Guardian noted , \" Ben <unk> and Robert <unk> offer <unk> amid the <unk> . \" \n",
            " \n",
            " = = = 2006 – present = = = \n",
            " \n",
            " In 2006 <unk> starred in the play <unk> written by Mark <unk> . The play was part of a series which featured different <unk> , titled Burn / <unk> / <unk> . In a 2006 interview , fellow actor Ben <unk> identified <unk> as one of his favorite co @-@ stars : \" I loved working with a guy called Robert <unk> , who was in the triple bill of Burn , <unk> and <unk> at the National . He played my brother in Mercury Fur . \" He portrayed \" Jason Tyler \" on the 2006 episode of the television series , Doctors , titled \" Something I <unk> \" . <unk> starred as \" William \" in the 2007 production of How to Curse directed by <unk> <unk> . How to Curse was performed at Bush Theatre in the London Borough of <unk> and Fulham . In a review of the production for The Daily Telegraph , theatre critic Charles Spencer noted , \" Robert <unk> brings a touching vulnerability to the stage as William . \" \n",
            " <unk> starred in two films in 2008 , <unk> <unk> by filmmaker Paris <unk> , and <unk> Punch directed by <unk> Blackburn . <unk> portrayed a character named \" Sean \" in <unk> Punch , who <unk> along with character \" Josh \" as the \" quiet brother ... who hits it off with <unk> \" . <unk> guest starred on a two @-@ part episode arc \" <unk> \" in May 2008 of the television series Waking the Dead as character \" Jimmy <unk> \" . He appeared on the television series <unk> as \" Neil \" in November 2008 . He had a recurring role in ten episodes of the television series <unk> in 2010 , as \" <unk> Fletcher \" . He portrayed an emergency physician applying for a medical <unk> . He commented on the inherent difficulties in portraying a physician on television : \" Playing a doctor is a strange experience . <unk> you know what you 're talking about when you don 't is very bizarre but there are advisers on set who are fantastic at taking you through procedures and giving you the confidence to stand there and look like you know what you 're doing . \" <unk> starred in the 2011 film <unk> directed by Paris <unk> . \n",
            " \n",
            " = = Filmography = = \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w7uB4GZ7Ke76",
        "colab_type": "text"
      },
      "source": [
        "The dataset is loaded again using the Dataset class from PyTorch. There are different options for constructing the dataset, e.g. the different sentence can be counted as separate instances, we can also iterate through the whole dataset, or a wiki document with a window of size L and count each window as an instance."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_IKUqTHWw6i",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class WikiDatasetReader(Dataset):\n",
        "  def __init__(self, file_name: str, vocab: Vocab, seq_len: int):\n",
        "    self.vocab = vocab\n",
        "\n",
        "    text = open(file_name).read()\n",
        "    text = text.replace('\\n', '<eos>')\n",
        "\n",
        "    # each document start with a title between two = signs, \n",
        "    # include <eos> to avoid matching subtitles (with more =)\n",
        "    wiki_docs = re.split(' = [^=]+ = <eos>', text)\n",
        "\n",
        "    self.dataset = []\n",
        "    for document in wiki_docs:\n",
        "      tokens = [token for token in document.split(' ') if len(token) > 0]\n",
        "\n",
        "      if len(tokens) <= 1:\n",
        "        # skip empty rows\n",
        "        continue\n",
        "\n",
        "      # iterate through the wiki document with a window of size seq_len\n",
        "      # each window is a separate instance\n",
        "      doc_instances = [tokens[i:i+seq_len] for i in range(0, len(tokens), seq_len)]\n",
        "\n",
        "      # pad the last window, which can be shorted than seq_len\n",
        "      doc_instances[-1] = doc_instances[-1] + ['<pad>'] * (seq_len - len(doc_instances[-1]))\n",
        "      self.dataset.extend(doc_instances)\n",
        "    \n",
        "    # truncate last incomplete batch (the hidden states for the RNN have the shape of the batch)\n",
        "    self.dataset = self.dataset[:(len(self.dataset)-(len(self.dataset) % batch_size))]\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.dataset)\n",
        "\n",
        "  def __getitem__(self, idx: int):\n",
        "    return self.vocab.to_ids(self.dataset[idx])"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBvvQHnm9COV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "771d5373-458d-4a1e-8fa4-40d318bf32ba"
      },
      "source": [
        "seq_len = 35\n",
        "batch_size = 128\n",
        "test_dataset = WikiDatasetReader('wiki.test.tokens', vocabulary, seq_len)\n",
        "\n",
        "print(test_dataset[0])\n",
        "print(vocabulary.to_words(test_dataset[0]))\n",
        "print()\n",
        "print(test_dataset[1])\n",
        "print(vocabulary.to_words(test_dataset[1]))"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 11, 25, 26, 27, 28, 29, 15, 30, 31, 32, 33, 18, 21]\n",
            "['<eos>', 'Robert', '<unk>', 'is', 'an', 'English', 'film', ',', 'television', 'and', 'theatre', 'actor', '.', 'He', 'had', 'a', 'guest', '@-@', 'starring', 'role', 'on', 'the', 'television', 'series', 'The', 'Bill', 'in', '2000', '.', 'This', 'was', 'followed', 'by', 'a', 'starring']\n",
            "\n",
            "[22, 28, 24, 34, 35, 36, 33, 37, 38, 10, 39, 31, 40, 28, 41, 42, 24, 43, 44, 45, 15, 16, 17, 18, 19, 22, 28, 24, 11, 25, 46, 47, 5, 28, 48]\n",
            "['role', 'in', 'the', 'play', 'Herons', 'written', 'by', 'Simon', 'Stephens', ',', 'which', 'was', 'performed', 'in', '2001', 'at', 'the', 'Royal', 'Court', 'Theatre', '.', 'He', 'had', 'a', 'guest', 'role', 'in', 'the', 'television', 'series', 'Judge', 'John', '<unk>', 'in', '2002']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LJfzyoT_FJ_V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def collate_batch_bilstm(input_ids: List) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    \"\"\"\n",
        "    Combines multiple data samples into a single batch\n",
        "    :param input_ids: The token input ids\n",
        "    :return: A tuple of tensors (input_ids, targets)\n",
        "    \"\"\"\n",
        "    input_data = torch.tensor(input_ids)\n",
        "    # we don't use the last position as there isn't anything left for generation\n",
        "    input_ids = input_data[:, :-1]\n",
        "    # the target at each step is to generate the next word from the sequence\n",
        "    # so we shift the token ids with 1 position\n",
        "    targets = input_data[:, 1:]\n",
        "    return input_ids, targets"
      ],
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SIS9JR_R-KCm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "outputId": "092382ee-b47b-4f22-e376-8773ce8a74a2"
      },
      "source": [
        "collate_batch_bilstm([test_dataset[0]])"
      ],
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[ 0,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,\n",
              "          21, 22, 23, 24, 11, 25, 26, 27, 28, 29, 15, 30, 31, 32, 33, 18]]),\n",
              " tensor([[ 4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21,\n",
              "          22, 23, 24, 11, 25, 26, 27, 28, 29, 15, 30, 31, 32, 33, 18, 21]]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 120
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SarUbfzEiA6M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "val_dataset = WikiDatasetReader('wiki.valid.tokens', vocabulary, seq_len)\n",
        "train_dataset = WikiDatasetReader('wiki.train.tokens', vocabulary, seq_len)"
      ],
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0cjbDzfJ3pE",
        "colab_type": "text"
      },
      "source": [
        "# Creating the model\n",
        "\n",
        "Next we will create an LSTM model. We again extend the PyTorch class `torch.nn.Module` and implement the `__init__` function, and define how tensors are processed in the `__forward__` function.\n",
        "\n",
        "**Question.** Why aren't we using a Bi-LSTM network for a Language Model?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qRuI--wZOsCY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the model\n",
        "class LSTMNetwork(nn.Module):\n",
        "    \"\"\"\n",
        "    Basic LSTM network\n",
        "    \"\"\"\n",
        "    def __init__(\n",
        "            self,\n",
        "            vocab_size: int, \n",
        "            embeddings_dim: int,\n",
        "            lstm_dim: int,       \n",
        "            n_words: int,      \n",
        "            dropout_prob: float = 0.0,\n",
        "            lstm_layers: int = 1,\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Initializer for basic BiLSTM network\n",
        "        :param pretrained_embeddings: A tensor containing the pretrained BPE embeddings\n",
        "        :param lstm_dim: The dimensionality of the BiLSTM network\n",
        "        :param dropout_prob: Dropout probability\n",
        "        :param n_classes: The number of output classes\n",
        "        \"\"\"\n",
        "\n",
        "        # First thing is to call the superclass initializer\n",
        "        super(LSTMNetwork, self).__init__()\n",
        "\n",
        "        # We'll define the network in a ModuleDict, which makes organizing the model a bit nicer\n",
        "        # The components are an embedding layer, a 2 layer LSTM, and a feed-forward output layer\n",
        "        self.vocab_size = vocab_size\n",
        "        self.model = nn.ModuleDict({\n",
        "            'embeddings': nn.Embedding(vocab_size, embeddings_dim),\n",
        "            'bilstm': nn.LSTM( \n",
        "                embeddings_dim,\n",
        "                lstm_dim,\n",
        "                num_layers=lstm_layers,\n",
        "                batch_first=True,\n",
        "                dropout=dropout_prob),\n",
        "            'ff': nn.Linear(lstm_dim, vocab_size),\n",
        "        })\n",
        "\n",
        "        # Initialize the weights of the model\n",
        "        self._init_weights()\n",
        "\n",
        "    def _init_weights(self):\n",
        "        all_params = list(self.model['bilstm'].named_parameters()) + \\\n",
        "                     list(self.model['ff'].named_parameters())\n",
        "        for n, p in all_params:\n",
        "            if 'weight' in n:\n",
        "                nn.init.xavier_normal_(p)\n",
        "            elif 'bias' in n:\n",
        "                nn.init.zeros_(p)\n",
        "\n",
        "    def forward(self, input_ids, hidden_states):\n",
        "        \"\"\"\n",
        "        Defines how tensors flow through the model\n",
        "        :param input_ids: (b x sl) The IDs into the vocabulary of the input samples\n",
        "        :param hidden_states: (b x sl) x 2 Hidden states for the LSTM model\n",
        "        :return: (lstm output, updated hidden stated)\n",
        "        \"\"\"\n",
        "\n",
        "        # Get embeddings (b x sl x edim)\n",
        "        embeds = self.model['embeddings'](input_ids)\n",
        "      \n",
        "        # Pass the sequence through the BiLSTM\n",
        "        lstm_out, hidden_states = self.model['bilstm'](embeds, hidden_states)\n",
        "        \n",
        "        lstm_out = lstm_out.reshape(lstm_out.size(0)*lstm_out.size(1), lstm_out.size(2))\n",
        "        lstm_out = self.model['ff'](lstm_out)\n",
        "\n",
        "        return lstm_out, hidden_states"
      ],
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q-l7gpJFNyfe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cpu\")\n",
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")"
      ],
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fY0EQ_YFLMos",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define some hyperparameters\n",
        "lr = 0.001\n",
        "n_epochs = 4\n",
        "lstm_dim = 1024\n",
        "lstm_layers = 1\n",
        "embeddings_dim = 128"
      ],
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fDdHYcJ-QRn9",
        "colab_type": "text"
      },
      "source": [
        "This is a utility function which will take a model and a validation dataloader and return the current perplexity of the model against that dataset. We can use this to know when to save the model and to perform early stopping if desired."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z2r3DzpSOq_l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def evaluate(model: nn.Module, valid_dl: DataLoader):\n",
        "  \"\"\"\n",
        "  Evaluates the model on the given dataset\n",
        "  :param model: The model under evaluation\n",
        "  :param valid_dl: A `DataLoader` reading validation data\n",
        "  :return: The accuracy of the model on the dataset\n",
        "  \"\"\"\n",
        "  model.eval()\n",
        "  loss_all = []\n",
        "  states = (torch.zeros(lstm_layers, batch_size, lstm_dim).to(device),\n",
        "              torch.zeros(lstm_layers, batch_size, lstm_dim).to(device))\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "        \n",
        "  with torch.no_grad():\n",
        "    for batch in tqdm(valid_dl, desc='Evaluation'):\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      input_ids = batch[0]\n",
        "      targets = batch[1]\n",
        "      states = detach(states)\n",
        "      logits, states = model(input_ids, states)\n",
        "      loss = loss_fn(logits, targets.reshape(-1))\n",
        "\n",
        "      loss_all.append(loss.detach().cpu().numpy())\n",
        "\n",
        "  perplexity = np.exp(sum(loss_all) / (len(loss_all)))\n",
        "  return perplexity"
      ],
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykX39dqiQ3qI",
        "colab_type": "text"
      },
      "source": [
        "Here we define the main training loop."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aKieRBZkghS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Truncated backpropagation\n",
        "def detach(states):\n",
        "    return [state.detach() for state in states]\n",
        "\n",
        "def train(\n",
        "    model: nn.Module, \n",
        "    train_dl: DataLoader, \n",
        "    valid_dl: DataLoader, \n",
        "    optimizer: torch.optim.Optimizer, \n",
        "    n_epochs: int, \n",
        "    device: torch.device\n",
        "):\n",
        "  \"\"\"\n",
        "  The main training loop which will optimize a given model on a given dataset\n",
        "  :param model: The model being optimized\n",
        "  :param train_dl: The training dataset\n",
        "  :param valid_dl: A validation dataset\n",
        "  :param optimizer: The optimizer used to update the model parameters\n",
        "  :param n_epochs: Number of epochs to train for\n",
        "  :param device: The device to train on\n",
        "  :return: (model, losses) The best model and the losses per iteration\n",
        "  \"\"\"\n",
        "\n",
        "  # Keep track of the loss and best accuracy\n",
        "  losses = []\n",
        "  best_perplexity = 300.0\n",
        "  # Set initial hidden and cell states\n",
        "  loss_fn = nn.CrossEntropyLoss()\n",
        "  # Iterate through epochs\n",
        "  for ep in range(n_epochs):\n",
        "    states = (torch.zeros(lstm_layers, batch_size, lstm_dim).to(device),\n",
        "              torch.zeros(lstm_layers, batch_size, lstm_dim).to(device))\n",
        " \n",
        "    loss_epoch = []\n",
        "\n",
        "    #Iterate through each batch in the dataloader\n",
        "    for batch in tqdm(train_dl):\n",
        "      # VERY IMPORTANT: Make sure the model is in training mode, which turns on \n",
        "      # things like dropout and layer normalization\n",
        "      model.train()\n",
        "\n",
        "      # VERY IMPORTANT: zero out all of the gradients on each iteration -- PyTorch\n",
        "      # keeps track of these dynamically in its computation graph so you need to explicitly\n",
        "      # zero them out\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "      # Place each tensor on the GPU\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      input_ids = batch[0]\n",
        "      targets = batch[1]\n",
        "      # Pass the inputs through the model, get the current loss and logits\n",
        "      states = detach(states)\n",
        "      logits, states = model(input_ids, states)\n",
        "      loss = loss_fn(logits, targets.reshape(-1))\n",
        "\n",
        "      losses.append(loss.item())\n",
        "      loss_epoch.append(loss.item())\n",
        "      \n",
        "      # Calculate all of the gradients and weight updates for the model\n",
        "      loss.backward()\n",
        "\n",
        "      # Optional: clip gradients\n",
        "      torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "      # Finally, update the weights of the model\n",
        "      optimizer.step()\n",
        "      #gc.collect()\n",
        "\n",
        "    # Perform inline evaluation at the end of the epoch\n",
        "    perplexity = evaluate(model, valid_dl)\n",
        "    print(f'Validation perplexity: {perplexity}, train loss: {sum(loss_epoch) / len(loss_epoch)}')\n",
        "\n",
        "    # Keep track of the best model based on the accuracy\n",
        "    best_model = model.state_dict()\n",
        "    if perplexity < best_perplexity:\n",
        "      best_model = model.state_dict()\n",
        "      best_perplexity = perplexity\n",
        "\n",
        "  model.load_state_dict(best_model)\n",
        "  return model, losses"
      ],
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ANhsatD4S4C5",
        "colab_type": "text"
      },
      "source": [
        "Now that we have the basic training and evaluation loops defined, we can create the datasets and optimizer and run it!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olm-iDPXvyxD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7280dd4-79ec-44f1-b74f-72344405cfc6"
      },
      "source": [
        "val_dataset = WikiDatasetReader('wiki.valid.tokens', vocabulary, seq_len)\n",
        "train_dataset = WikiDatasetReader('wiki.train.tokens', vocabulary, seq_len)\n",
        "\n",
        "valid_dl = DataLoader(val_dataset, batch_size=batch_size, collate_fn=collate_batch_bilstm, num_workers=8)\n",
        "train_dl = DataLoader(train_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch_bilstm, num_workers=8)\n",
        "\n",
        "print(len(vocabulary.word2idx))"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "33280\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng2Ka6TcVMw5",
        "colab_type": "text"
      },
      "source": [
        "Link to a trained model's weights: https://drive.google.com/file/d/1yHVG5Ck5NDSeu1ANGCNnklK-rD98F8rE/view?usp=sharing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJCaeC67kaWS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "675a8fe4-e0c2-49d8-bb79-edf13daff5ea"
      },
      "source": [
        "# Create the dataset readers\n",
        "# dataset loaded lazily with N workers in parallel\n",
        "\n",
        "model = LSTMNetwork(\n",
        "    embeddings_dim=embeddings_dim,\n",
        "    vocab_size = len(vocabulary.word2idx),\n",
        "    lstm_dim=lstm_dim, \n",
        "    dropout_prob=0.1, \n",
        "    n_words=seq_len, \n",
        "    lstm_layers=lstm_layers\n",
        "  ).to(device)\n",
        "\n",
        "# Create the optimizer\n",
        "optimizer = Adam(model.parameters(), lr=lr)\n",
        "\n",
        "# Train\n",
        "model, losses = train(model, train_dl, valid_dl, optimizer, n_epochs, device)\n",
        "# model.load_state_dict(torch.load('best_model_wiki'))"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/rnn.py:60: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.1 and num_layers=1\n",
            "  \"num_layers={}\".format(dropout, num_layers))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RTg5zq-wsD8v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'best_model_wiki')"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s2Jiw-ssYc-u",
        "colab_type": "text"
      },
      "source": [
        "Next we can plot the loss curve"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-zuTelyYZgb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "outputId": "257526e5-d8a1-4859-ffe8-09abf7bee604"
      },
      "source": [
        "plt.plot(losses)"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f29231b35f8>]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 130
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RcixkfU80Ysn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 83,
          "referenced_widgets": [
            "07c71aa27af74d50aeb88fba1bf9f21b",
            "7aa90a2c194345c4a17b421278fa5c4b",
            "1cdc9528fc3a48f285357816ffd71ae5",
            "08e1fb8dbeb7489aba0abf370b311f9d",
            "6564444f31974cb0ade65b26e44162ad",
            "826b133eeba34e0d801113b50aee84b6",
            "9a3c3bd03808430984b5c4c4038e885a",
            "9fa6dd95cdbd43af9d27c93c54fc28e2"
          ]
        },
        "outputId": "b953cc71-b727-44d2-f6ed-81bb6692532b"
      },
      "source": [
        "test_dl = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_batch_bilstm, num_workers=8)\n",
        "\n",
        "evaluate(model, test_dl)"
      ],
      "execution_count": 161,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "07c71aa27af74d50aeb88fba1bf9f21b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Evaluation', max=54.0, style=ProgressStyle(description_wi…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "323.59962259115355"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 161
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vl4M__ud8Eae",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c7d17a83-91cc-4023-ea61-95f40e789dde"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive') "
      ],
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "axW4Aq6l7lEl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5b055f25-106d-4c6d-b3b0-4fdb8f596895"
      },
      "source": [
        "model.load_state_dict(torch.load('drive/My Drive/best_model_wiki'))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 154
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H3Qs51Aec229",
        "colab_type": "text"
      },
      "source": [
        "![Results on dataset](https://c1.sfdcstatic.com/content/dam/web/en_us/www/images/einstein/publications/wikitext-2.png)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rAz0e0E00u76",
        "colab_type": "text"
      },
      "source": [
        "Steps for improvement\n",
        "- Use a larger dataset.\n",
        "- Preprocess the dataset for artifacts and use a smarter splitting to documents and/or sentences.\n",
        "- Check any of the papers above or other papers for parameters that work best on the dataset you've chosen\n",
        "- Use the packing technique to tell the RNN to avoid making steps over padding tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TAkMtao5SEYA",
        "colab_type": "text"
      },
      "source": [
        "### Generation of text\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NTbRuE29SB_T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7d86c2e5-11d0-4793-e45e-9fba0521008e"
      },
      "source": [
        "states = (torch.zeros(lstm_layers, 1, lstm_dim).to(device),\n",
        "              torch.zeros(lstm_layers, 1, lstm_dim).to(device))\n",
        "\n",
        "sentence_start = 'Robert is the name of a famous'\n",
        "unk_token_id = vocabulary.word2idx['<unk>']\n",
        "new_token = None\n",
        "\n",
        "while new_token != '<eos>' and len(sentence_start.split()) < 29:\n",
        "  tokens = sentence_start.split()\n",
        "  token_idx = len(tokens)\n",
        "\n",
        "  tokens = tokens + ['<pad>'] * (seq_len - len(tokens))\n",
        "\n",
        "  token_ids = [vocabulary.word2idx.get(token,unk_token_id) for token in tokens]\n",
        "  batch = collate_batch_bilstm([token_ids])\n",
        "\n",
        "  logits, states = model(batch[0].to(device), states)\n",
        "  logits = logits.detach().cpu().numpy()[token_idx]\n",
        "  \n",
        "\n",
        "  new_token_id = np.argmax(logits)\n",
        "  new_token = vocabulary.idx2word[new_token_id]\n",
        "  sentence_start = sentence_start + ' ' + new_token\n",
        "  print('\\r'+sentence_start, end='')"
      ],
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rRobert is the name of a famous series\rRobert is the name of a famous series \"\rRobert is the name of a famous series \" \"\rRobert is the name of a famous series \" \" \"\rRobert is the name of a famous series \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \"\rRobert is the name of a famous series \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \" \""
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1JEopLHVTyKf",
        "colab_type": "text"
      },
      "source": [
        "## Check perplexity of a sentence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ptMZ6wrYT1KZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_sentence_perplexity(sentence, model, vocabulary, seq_len):\n",
        "  states = (torch.zeros(lstm_layers, 1, lstm_dim).to(device),\n",
        "              torch.zeros(lstm_layers, 1, lstm_dim).to(device))\n",
        "  unk_token_id = vocabulary.word2idx['<unk>']\n",
        "\n",
        "  tokens = sentence.split()\n",
        "  tokens = tokens[:seq_len]\n",
        "  tokens = tokens + ['<pad>'] * (seq_len - len(tokens))\n",
        "  token_ids = [vocabulary.word2idx.get(token,unk_token_id) for token in tokens]\n",
        "\n",
        "  batch = collate_batch_bilstm([token_ids])\n",
        "  loss_fn = torch.nn.CrossEntropyLoss()\n",
        "  logits, states = model(batch[0].to(device), states)\n",
        "  loss = loss_fn(logits, batch[1].to(device).reshape(-1))\n",
        "  loss = loss.detach().cpu().numpy()\n",
        "  return np.exp(loss)"
      ],
      "execution_count": 158,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nz9VeUg2jypl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d80c5443-14cd-4b53-bb5f-8551c0346d6f"
      },
      "source": [
        "get_sentence_perplexity('I want to buy some potatoes from the airport.', model, vocabulary, seq_len)"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.8525624"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AklQNHQrYfk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1dfdf0ed-7432-49de-ea77-861fb21cea3d"
      },
      "source": [
        "get_sentence_perplexity('jibberish ? . something something is', model, vocabulary, seq_len)"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6.7407804"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 160
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtHm1h11KAEJ",
        "colab_type": "text"
      },
      "source": [
        "References:\n",
        "- Bucket Iterator https://torchtext.readthedocs.io/en/latest/data.html#bucketiterator\n",
        "- Packing https://github.com/HarshTrivedi/packing-unpacking-pytorch-minimal-tutorial"
      ]
    }
  ]
}