{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%%html\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    },
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Interpretability\n",
    "\n",
    "or: _putting the __science__ in data science (and NLP)_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "* Motivation (10 min.)\n",
    "* Probes (20 min.)\n",
    "* Adversaries (10 min.)\n",
    "* Visualization (10 min.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Motivation\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/acl_2020_interpretability_tutorial-4-12.pdf\">\n",
    "    <img src=\"https://4.bp.blogspot.com/-dfHBPg2rXcA/UC4v-5OPXhI/AAAAAAAAHic/EMCX2mOV8Go/s1600/ikea-00-instructions-orig.png\" width=70%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Belinkov, Gehrmann and Pavlick, 2020](https://www.aclweb.org/anthology/2020.acl-tutorials.1.pdf); [slides](https://sebastiangehrmann.com/assets/files/acl_2020_interpretability_tutorial.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Opening the black box\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/cs224n-2020-lecture20-interpretability-5-9.pdf\">\n",
    "    <img src=\"https://imgs.xkcd.com/comics/machine_learning.png\" width=70%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from John Hewitt; [slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture20-interpretability.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Probing MT models\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/acl_2020_interpretability_tutorial-24-34.pdf\">\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/fc4bfa761f888806eea985e5fe6d16f83af93a10/4-Figure4-1.png\" width=70%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Belinkov, Gehrmann and Pavlick, 2020](https://www.aclweb.org/anthology/2020.acl-tutorials.1.pdf); [slides](https://sebastiangehrmann.com/assets/files/acl_2020_interpretability_tutorial.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Language models as linguistic test subjects\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/cs224n-2020-lecture20-interpretability-14-21.pdf\">\n",
    "    <img src=\"https://paeaonline.org/wp-content/uploads/2015/09/multiple-choice-757x426.jpg\" width=70%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from John Hewitt; [slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture20-interpretability.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Designing probes\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/acl_2020_interpretability_tutorial-80-98.pdf\">\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/9d87300892911275520a4f7a5e5abf4f1c002fec/2-Figure1-1.png\" width=70%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Belinkov, Gehrmann and Pavlick, 2020](https://www.aclweb.org/anthology/2020.acl-tutorials.1.pdf); [slides](https://sebastiangehrmann.com/assets/files/acl_2020_interpretability_tutorial.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Adversarial examples\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/2de50c0f27cdcc6cb000f3b67825d95f7d1ed2c5/1-Figure1-1.png\" width=70%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Abdou et al., 2020](https://www.aclweb.org/anthology/2020.acl-main.679.pdf)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Adversarial examples\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/2de50c0f27cdcc6cb000f3b67825d95f7d1ed2c5/8-Figure4-1.png\" width=90%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Abdou et al., 2020](https://www.aclweb.org/anthology/2020.acl-main.679.pdf)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Visualization\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/acl_2020_interpretability_tutorial-117-121.pdf\">\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/fafb602db42240f5fb1e1b113fa0ed8647b45adc/8-Figure5-1.png\" width=70%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Belinkov, Gehrmann and Pavlick, 2020](https://www.aclweb.org/anthology/2020.acl-tutorials.1.pdf); [slides](https://sebastiangehrmann.com/assets/files/acl_2020_interpretability_tutorial.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Close inspection\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/cs224n-2020-lecture20-interpretability-26-32.pdf\">\n",
    "    <img src=\"https://www.parismou.org/sites/default/files/inspections_1.jpg\" width=30%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from John Hewitt; [slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture20-interpretability.pdf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Attention is not explanation\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/1e83c20def5c84efa6d4a0d80aa3159f55cb9c3f/1-Figure1-1.png\" width=80%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Jain and Wallace, 2019](https://www.aclweb.org/anthology/N19-1357.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Attention is not not explanation\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/ce177672b00ddf46e4906157a7e997ca9338b8b9/3-Table1-1.png\" width=80%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Wiegreffe and Pinter, 2019](https://www.aclweb.org/anthology/D19-1002.pdf))\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### LIME\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/5091316bb1c6db6c6a813f4391911a5c311fdfe0/4-Figure2-1.png\" width=90%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Ribeiro et al., 2016](https://www.kdd.org/kdd2016/papers/files/rfp0573-ribeiroA.pdf)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Meta-analyses and tools\n",
    "\n",
    "<center>\n",
    "    <a href=\"slides/cs224n-2020-lecture20-interpretability-110-112.pdf\">\n",
    "    <img src=\"https://demo.allennlp.org/static/media/allennlp_logo.a93e4abe.svg\" width=30%>\n",
    "    </a>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from John Hewitt; [slides](http://web.stanford.edu/class/cs224n/slides/cs224n-2020-lecture20-interpretability.pdf))\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### MRC demo\n",
    "\n",
    "### https://demo.allennlp.org/reading-comprehension/MjMzNTgxOA=="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Further reading\n",
    "\n",
    "- [Belinkov and Glass, 2020. Analysis Methods in Neural Language Processing: A Survey](https://www.aclweb.org/anthology/Q19-1004.pdf)\n",
    "- [Hewitt, 2020. Designing and Interpreting Probes](https://nlp.stanford.edu//~johnhew//interpreting-probes.html)\n",
    "- [Lawrence, 2020. Interpretability and Analysis of Models for NLP @ ACL 2020](https://medium.com/@lawrence.carolin/interpretability-and-analysis-of-models-for-nlp-e6b977ac1dc6)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}