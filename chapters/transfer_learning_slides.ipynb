{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "  function code_toggle() {\n",
       "    if (code_shown){\n",
       "      $('div.input').hide('500');\n",
       "      $('#toggleButton').val('Show Code')\n",
       "    } else {\n",
       "      $('div.input').show('500');\n",
       "      $('#toggleButton').val('Hide Code')\n",
       "    }\n",
       "    code_shown = !code_shown\n",
       "  }\n",
       "\n",
       "  $( document ).ready(function(){\n",
       "    code_shown=false;\n",
       "    $('div.input').hide()\n",
       "  });\n",
       "</script>\n",
       "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
       "<style>\n",
       ".rendered_html td {\n",
       "    font-size: xx-large;\n",
       "    text-align: left; !important\n",
       "}\n",
       ".rendered_html th {\n",
       "    font-size: xx-large;\n",
       "    text-align: left; !important\n",
       "}\n",
       "</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%html\n",
    "<script>\n",
    "  function code_toggle() {\n",
    "    if (code_shown){\n",
    "      $('div.input').hide('500');\n",
    "      $('#toggleButton').val('Show Code')\n",
    "    } else {\n",
    "      $('div.input').show('500');\n",
    "      $('#toggleButton').val('Hide Code')\n",
    "    }\n",
    "    code_shown = !code_shown\n",
    "  }\n",
    "\n",
    "  $( document ).ready(function(){\n",
    "    code_shown=false;\n",
    "    $('div.input').hide()\n",
    "  });\n",
    "</script>\n",
    "<form action=\"javascript:code_toggle()\"><input type=\"submit\" id=\"toggleButton\" value=\"Show Code\"></form>\n",
    "<style>\n",
    ".rendered_html td {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    ".rendered_html th {\n",
    "    font-size: xx-large;\n",
    "    text-align: left; !important\n",
    "}\n",
    "</style>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "heading_collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    },
    "run_control": {
     "frozen": false,
     "read_only": false
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tikzmagic extension is already loaded. To reload it, use:\n",
      "  %reload_ext tikzmagic\n"
     ]
    }
   ],
   "source": [
    "%load_ext tikzmagic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recent Topics in NLP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Outline\n",
    "\n",
    "- Natural language inference (15 min.)\n",
    "- Transfer learning (15 min.)\n",
    "- Multi-task benchmarks (15 min.)\n",
    "- Break (10 min.)\n",
    "- Interpretability ([slides](interpretability_slides.ipynb))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Recognizing Textual Entailment = Natural Language Inference\n",
    "\n",
    "Determining the logical relationship between two sentences.\n",
    "\n",
    "- Classification task\n",
    "- Requires commonsense and world knowledge\n",
    "- Requires general natural language understanding\n",
    "- Requires fine-grained reasoning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Recognizing Textual Entailment (RTE)\n",
    "\n",
    "[Dagan et al., 2005](http://u.cs.biu.ac.il/~nlp/downloads/publications/RTEChallenge.pdf)\n",
    "\n",
    "- Text (premise) T\n",
    "- Hypothesis H\n",
    "\n",
    "T entails H if, typically, a human reading T would infer that H is most likely true."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **T:** “Google files for its long awaited IPO.”\n",
    "> **H:** “Google goes public.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Positive ($\\Rightarrow$, entails)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **T:** “Regan attended a ceremony in Washington to commemorate the landings in Normandy.”\n",
    "> **H:** “Washington is located in Normandy.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Negative ($\\not\\Rightarrow$, does not entail)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Stanford Natural Language Inference (SNLI) corpus\n",
    "\n",
    "[Bowman et al., 2015](https://www.aclweb.org/anthology/D15-1075.pdf): crowdsourced NLI using image captions.\n",
    "\n",
    "570K sentence pairs, two orders of magnitude larger than other NLI resources (1K-10K examples).\n",
    "\n",
    "**T**: A wedding party taking pictures\n",
    "- **H:** There is a funeral\t\t\t\t\t: **<span class=red>Contradiction</span>** ($\\Rightarrow\\neg$)\n",
    "- **H:** They are outside\t\t\t\t\t    : **<span class=blue>Neutral</span>** (?)\n",
    "- **H:** Someone got married\t\t\t\t    : **<span class=green>Entailment</span>** ($\\Rightarrow$)\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/3/31/Wedding_photographer_at_work.jpg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Multi-NLI (MNLI)\n",
    "\n",
    "[Williams et al., 2018](https://www.aclweb.org/anthology/N18-1101.pdf): more diverse domains.\n",
    "\n",
    "> **T:** “The legislation was widely hailed as a model for the country.”\n",
    "> **H:** “Many people thought the legislation was a model for the country.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Entailment ($\\Rightarrow$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **T:** “The program has helped victims in 90 court cases, and 150 legal counseling sessions have been held there.”\n",
    "> **H:** “Victims from 90 grand jury court cases were helped by the program.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neutral (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **T:** “As a result, Chris Schneider, executive director of Central California Legal Services, is building a lawsuit against Alpaugh Irrigation.”\n",
    "> **H:** “Central California Legal Services’ executive director decided not to pursue a lawsuit against Alpaugh Irrigation.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Contradiction ($\\Rightarrow\\neg$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "## RTE/NLI state of the art until 2015\n",
    "\n",
    "[Lai and Hockenmaier, 2014](https://www.aclweb.org/anthology/S14-2055.pdf),\n",
    "[Jimenez et al., 2014](https://www.aclweb.org/anthology/S14-2131.pdf),\n",
    "[Zhao et al., 2014](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6889713),\n",
    "[Beltagy et al., 2016](https://www.aclweb.org/anthology/J16-4007.pdf) and others:\n",
    "engineered pipelines.\n",
    "\n",
    "- Various external resources\n",
    "- Specialized subcomponents\n",
    "- Extensive use of **features**:\n",
    "  - Negation detection, word overlap, part-of-speech tags, dependency parses, alignment, symbolic meaning representation\n",
    "  \n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/fca1e631b8f93036065311eb92727c509423475a/9-Figure1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **T:** “The program has helped victims in 90 court cases, and 150 legal counseling sessions have been held there.”\n",
    "> **H:** “Victims from 90 grand jury court cases were helped by the program.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Neutral (?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "> **T:** “As a result, Chris Schneider, executive director of Central California Legal Services, is building a lawsuit against Alpaugh Irrigation.”\n",
    "> **H:** “Central California Legal Services’ executive director decided not to pursue a lawsuit against Alpaugh Irrigation.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Contradiction ($\\Rightarrow\\neg$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## RTE/NLI state of the art until 2015\n",
    "\n",
    "[Lai and Hockenmaier, 2014](https://www.aclweb.org/anthology/S14-2055.pdf),\n",
    "[Jimenez et al., 2014](https://www.aclweb.org/anthology/S14-2131.pdf),\n",
    "[Zhao et al., 2014](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=6889713),\n",
    "[Beltagy et al., 2016](https://www.aclweb.org/anthology/J16-4007.pdf) and others:\n",
    "engineered pipelines.\n",
    "\n",
    "- Various external resources\n",
    "- Specialized subcomponents\n",
    "- Extensive use of **features**:\n",
    "  - Negation detection, word overlap, part-of-speech tags, dependency parses, alignment, symbolic meaning representation\n",
    "  \n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/fca1e631b8f93036065311eb92727c509423475a/9-Figure1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Neural networks for NLI\n",
    "\n",
    "Large-scale NLI corpora: NNs are feasible to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "### Independent sentence encoding\n",
    "\n",
    "[Bowman et al, 2015](https://www.aclweb.org/anthology/D15-1075.pdf): same LSTM encodes premise and hypothesis.\n",
    "\n",
    "<img src=\"dl-applications-figures/rte.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "Last output vector as sentence representation.\n",
    "\n",
    "<img src=\"dl-applications-figures/rte_encoding.svg\" width=1500/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "MLP to classify as entailment/neutral/contradiction.\n",
    "\n",
    "<img src=\"dl-applications-figures/mlp.svg\" width=1400/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Conditional encoding\n",
    "\n",
    "The way we read the hypothesis could be influenced by our understanding of the premise.\n",
    "\n",
    "<img src=\"dl-applications-figures/conditional.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/conditional_encoding.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Conditional endcoding</td>\n",
    "<td>81.4</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "> You can’t cram the meaning of a whole\n",
    "%&!\\$# sentence into a single \\$&!#* vector!\n",
    ">\n",
    "> -- <cite>Raymond J. Mooney</cite>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Attention\n",
    "\n",
    "<img src=\"dl-applications-figures/attention.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hide_input": true,
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/attention_encoding.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img  src=\"./dl-applications-figures/camel.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Contextual understanding\n",
    "\n",
    "<img src=\"./dl-applications-figures/pink.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Conditional encoding</td>\n",
    "<td>81.4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Attention</td>\n",
    "<td>82.3</td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Fuzzy attention\n",
    "\n",
    "<img  src=\"./dl-applications-figures/mimes.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### Word-by-word attention\n",
    "\n",
    "<img src=\"dl-applications-figures/word_attention.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "<img src=\"dl-applications-figures/word_attention_encoding.svg\" width=1500/> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Reordering\n",
    "\n",
    "<img src=\"./dl-applications-figures/reordering.png\" width=60%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Synonyms\n",
    "\n",
    "<img  src=\"./dl-applications-figures/trashcan.png\" width=90%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Hypernyms\n",
    "\n",
    "<img src=\"./dl-applications-figures/kids.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "#### Lexical inference\n",
    "\n",
    "<img src=\"./dl-applications-figures/snow.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Results\n",
    "\n",
    "<table style=\"font-size: 28px; border-style: solid;\">\n",
    "<thead>\n",
    "<tr>\n",
    "<th>Model</th>\n",
    "<th>SNLI Test Score</th>\n",
    "</tr>\n",
    "</thead>\n",
    "<tbody>\n",
    "<tr>\n",
    "<td>LSTM</td>\n",
    "<td>77.6</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Conditional encoding</td>\n",
    "<td>81.4</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Attention</td>\n",
    "<td>82.3</td>\n",
    "</tr>\n",
    "<tr>\n",
    "<td>Word-by-word attention</td>\n",
    "<td><strong>83.5</strong></td>\n",
    "</tr>\n",
    "</tbody>\n",
    "</table>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Composition\n",
    "\n",
    "[Bowman et al., 2016](https://www.aclweb.org/anthology/P16-1139.pdf):\n",
    "compositional vector representation based on syntactic structure.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/36c097a225a95735271960e2b63a2cb9e98bff83/1-Figure1-1.png\" width=80%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    },
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NLI artefacts\n",
    "\n",
    "SNLI and MNLI are **crowdsourced**.\n",
    "\n",
    "[Gururangan et al., 2018](https://www.aclweb.org/anthology/N18-2017.pdf): hypothesis phrasing alone gives out the class.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/2997b26ffb8c291ce478bd8a6e47979d5a55c466/2-Table1-1.png\" width=150%/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Lexical entailment\n",
    "\n",
    "[Glockner et al., 2018](https://www.aclweb.org/anthology/P18-2103.pdf): very **simple** examples that are hard for models.\n",
    "\n",
    "<img src=\"https://persagen.com/files/misc/arxiv1805.02266-table1.png\" width=80%>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Transfer learning\n",
    "\n",
    "<img src=\"https://ruder.io/content/images/2019/08/transfer_learning_taxonomy.png\" width=45%>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multi-task learning\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/161ffb54a3fdf0715b198bb57bd22f910242eb49/19-Figure1.2-1.png\" width=45%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Caruana, 1997](https://www.cs.cornell.edu/~caruana/mlj97.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Multi-task learning\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/161ffb54a3fdf0715b198bb57bd22f910242eb49/44-Figure2.3-1.png\" width=60%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Caruana, 1997](https://www.cs.cornell.edu/~caruana/mlj97.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NLP from scratch\n",
    "\n",
    "Architecture for POS tagging, chunking, NER, SRL as sequence labeling.\n",
    "\n",
    "Key insight: it's better to share **embeddings**.\n",
    "\n",
    "<table>\n",
    "<tr>\n",
    "<td><img src=\"https://blog.acolyer.org/wp-content/uploads/2016/07/nlu-from-scratch-fig-2.png\" width=100%/></td>\n",
    "<td><img src=\"https://files.speakerdeck.com/presentations/56645956135848559b3003875a350fde/slide_48.jpg\" width=100%/></td>\n",
    "</tr>\n",
    "</table>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Collobert et al., 2011](https://jmlr.org/papers/volume12/collobert11a/collobert11a.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "# Pre-trained embeddings\n",
    "\n",
    "General-purpose representations trained on large datasets (usually unsupervised):\n",
    "\n",
    "- [word2vec](https://arxiv.org/pdf/1301.3781.pdf)\n",
    "- [GloVe](https://www.aclweb.org/anthology/D14-1162.pdf)\n",
    "- [ELMo](https://www.aclweb.org/anthology/N18-1202.pdf)\n",
    "- [BERT](https://www.aclweb.org/anthology/N19-1423.pdf)\n",
    "\n",
    "are all forms of transfer learning.\n",
    "\n",
    "<center>\n",
    "    <img src=\"mt_figures/bert_gpt_elmo.png\" width=100%>\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MTL: NLI and transition-based parsing\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/36c097a225a95735271960e2b63a2cb9e98bff83/2-Figure2-1.png\" width=150%/>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Bowman et al., 2016](https://www.aclweb.org/anthology/P16-1139.pdf))\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MTL with overlapping labels\n",
    "\n",
    "Sentiment analysis, stance detection, fake news detection and NLI\n",
    "with a Label Embedding Layer.\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/64c5f7055b2e6982b6b95e069b22230d13a134bb/4-Figure1-1.png\" width=150%/>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Augenstein et al., 2018](https://www.aclweb.org/anthology/N18-1172.pdf))\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Many-task MTL\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/ade0c116120b54b57a91da51235108b75c28375a/1-Figure1-1.png\" width=50%/>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Hashimoto et al, 2017](https://www.aclweb.org/anthology/D17-1206.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## When is MTL beneficial?\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/1b02204b210f822dabf8d68b7e3ea7ac14ee1268/4-Figure1-1.png\" width=50%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Bingel and Søgaard, 2017](https://www.aclweb.org/anthology/E17-2026.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MTL parsing\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://d3i71xaburhd42.cloudfront.net/9c852275f3dc176f1fbed0741201f352ec49adc1/5-Figure3-1.png\" width=90%>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Hershcovich and Arviv, 2019](https://www.aclweb.org/anthology/K19-2002.pdf);\n",
    "    also \n",
    "    [Hershcovich et al., 2018](https://www.aclweb.org/anthology/P18-1035.pdf),\n",
    "    [Arviv et al., 2020](https://arxiv.org/pdf/2010.05710.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## GLUE benchmark\n",
    "\n",
    "[Wang et al., 2019](https://openreview.net/pdf?id=rJ4km2R5t7): collection of sentence- and sentence-pair-classification tasks.\n",
    "\n",
    "<img src=\"https://d3i71xaburhd42.cloudfront.net/6aa371f872f49eb69a6ad185c74194d95c01257f/6-Table2-1.png\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### GLUE: Winograd NLI (WNLI)\n",
    "\n",
    "World knowledge and logical reasoning, presented as NLI.\n",
    "\n",
    "Positive:\n",
    "\n",
    "> “I put the cake away in the refrigerator. It has a lot of butter in it.”\n",
    "\n",
    "<center>\n",
    "$\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “The cake has a lot of butter in it.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "source": [
    "Negative:\n",
    "\n",
    "> “The large ball crashed right through the table because it was made of styrofoam.”\n",
    "\n",
    "<center>\n",
    "$\\not\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “The large ball was made of styrofoam.”"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## GLUE benchmark\n",
    "\n",
    "https://gluebenchmark.com/leaderboard\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://creatext.ai/static/img/blog/glue_performance_1.png\" width=150%/>\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Wang et al., 2019](https://papers.nips.cc/paper/8589-superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems.pdf))\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### SuperGLUE\n",
    "\n",
    "Harder NLI, for a meaningful comparison.\n",
    "\n",
    "https://super.gluebenchmark.com/leaderboard\n",
    "\n",
    "> “Dana Reeve, the widow of the actor Christopher Reeve, has died of lung cancer at age 44, according to the Christopher Reeve Foundation.”\n",
    "\n",
    "<center>\n",
    "$\\not\\Rightarrow$\n",
    "</center>\n",
    "\n",
    "> “Christopher Reeve had an accident.”\n",
    "\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Wang et al., 2019](https://papers.nips.cc/paper/8589-superglue-a-stickier-benchmark-for-general-purpose-language-understanding-systems.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### XTREME\n",
    "\n",
    "Collection of multilingual multi-task benchmarks.\n",
    "\n",
    "* Including TyDiQA-GoldP!\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://1.bp.blogspot.com/-5J6e2txWChk/XpSc_BaYFnI/AAAAAAAAFss/QCLROHrEutAN3GvOyfRzK8J7DA9yLY5GACLcBGAsYHQ/s640/XTREME%2BStill%2Bart_04%2Broboto.png\" width=\"70%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Hu et al., 2020](https://arxiv.org/pdf/2003.11080.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### XTREME\n",
    "\n",
    "<center>\n",
    "    <img src=\"https://1.bp.blogspot.com/-yzWzRs2bK7Y/Xn1Amrk3aaI/AAAAAAAAFkM/ClIN7fAeuLgulexicZhotwPXqTLNqGUPQCLcBGAsYHQ/s640/image1.gif\" width=\"70%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Hu et al., 2020](https://arxiv.org/pdf/2003.11080.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### XTREME\n",
    "\n",
    "Strategies:\n",
    "* Multilingual encoder (mBERT, XLM, **XLM-R**, MMTE)\n",
    "* Translate-train\n",
    "* Translate-test\n",
    "* In-language\n",
    "* Multi-task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### XTREME\n",
    "\n",
    "https://sites.research.google/xtreme\n",
    "\n",
    "<center>\n",
    "    <img src=\"dl-applications-figures/xtreme.png\" width=\"70%\">\n",
    "</center>\n",
    "\n",
    "<div style=\"text-align: right;\">\n",
    "    (from [Hu et al., 2020](https://arxiv.org/pdf/2003.11080.pdf))\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Further reading\n",
    "\n",
    "- [Ruder, 2017. An Overview of Multi-Task Learning in Deep Neural Networks](https://ruder.io/multi-task/)\n",
    "- [Ruder, 2019. The State of Transfer Learning in NLP](https://ruder.io/state-of-transfer-learning-in-nlp/)\n",
    "- [Liu et al., 2019. Linguistic Knowledge and Transferability of Contextual Representations](https://www.aclweb.org/anthology/N19-1112.pdf)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
